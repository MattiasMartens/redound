- Backpressure in the case of multiple subscribers
  - Principle of least astonishment: probably manage backpressure independently for each subscriber. In some cases this could cause sync issues where two subscribers feed into a single consumer; that's where the runtime clock comes in.
- Errors: we want a clean, standardized paradigm for handling event processing errors and when to terminate sources based on failures in their downstream. It's already established that errors don't propagate directly, but that it is a separate concern handled by the owner of all application sources and sinks.
- Push: nice to be able to synthesize events at a source and then push them upstream to a source so as to induce the data change that would have produced the event. Probably not a concern except in the context of source-capable derivations.
- Source capability: some derivations may use IO in the implementation of their underlying data structure. What this means, in effect, is that their derived data is cached and persists beyond the current runtime. This is useful in the context of extremely large datasets, where sources must use a pull-focused approach instead of querying everything, and some derivations exist that must aggregate source data that is not available in the current runtime. In this case, it also becomes valuable to apply queries to the derivation directly, instead of applying them to the source and waiting for their effects to propagate down. (Of course only the latter approach guarantees that the values are up-to-date, unless the framework user takes extra precautions.) But this also raises the question of if pull-capable derivations should also be push-capable. If they are push-capable, then the derived data can be updated directly as the user wishes to change it. But this means that a derivation can get ahead of its source, or even diverge from its source, which could lead to horrible chaos. This is basically the problem of a computed value with a setter, but in a distributed context. The way to avoid all this is for derivation push operations to always push to their sources, not themselves. The derivation is then updated in the normal way as the source propagates. But between the necessary source and the derivation lies any number of intermediate derivations. So finding the true sources is non-trivial. Also, derivations are meant to be optimally generic and composable. Requiring them to be aware of their sources introduces harmful coupling. For all these reasons, push capability on derivations seems like a bad idea. If push capability is desired, the derivation's downstream part should graduate to a source, and the derivation's upstream part should instead be a sink that generates push events on the new source.
6. The Redound paradigm should produce unidirectional graphs, hence, no cycles. However, it is hard in general to identify this so the framework can complain preemptively and accurately instead of breaking.
7. It's inevitable that apps will write to the same data source they read from. In most cases this is fine. However, it raises the possibility of apps creating infinite loops whose connections extend beyond the current runtime. Hopefully Redound will make this less likely, not more likely. But this should be considered.
8. 'seal' capability: sources should be able to unilaterally indicate that they will not yield any more events. The controller can then decide whether to end the source with an Outcome.
9. Broad-scope tasks: when a query ends, or a source is sealed, the controller may need to wait until all sinks have fully processed the events before capturing an outcome. A derivation is obligated to emit events in order of receipt, but it's not obligated to re-emit all events. How does the sink know that it's received everything it's going to? The only robust solution that comes to mind is for the 'seal' flag to also propagate downstream. But this too poses problems in the case of a derivation that accepts multiple sources. Should a derivation pass on 'seal' if just one source is sealed? Proposal: a so-called 'non-event' type is needed to express the fact that an event is deliberately not passed downstream so that the downstream clocks can be updated. From the perspective of implementors, this is a bloody pain. The abstract contract can require this but there should be a wrapper that encapsulates the guarantee that, once a Derivation's 'consume' promise is resolved, all events have therefore been processed. Then the framework can emit the non-events as necessary. (The main case where this is relevant is Batch transform, where the Derivation must emit events outside of the normal backpressure loop. Also - because of the existence of things like the Batch transform, the non-event paradigm does not totally obviate the propagation of Seal.)
10. To infer when events are fully received, it is necessary for events to carry a 'provenance' that maps their sources to the highest event tick the event is derived from. This works because Derivations must emit events in order of receipt, so the highest tick is the only one that's needed (including 'void' events). It may, however, introduce considerable overhead.
11. Do we care about allowing links in the graph to be asynchronous? In theory, the Redound paradigm should support distributed systems. But the clock stamp concept is not strong enough to support this: asynchronous events may be transmitted through a medium that causes them to arrive out-of-order, falsifying guarantees that are necessary to the integrity of the whole. Solution: each source must have its own unique clock, rather than a global clock. Then the identity of events is derived not from the tick alone but from the tick plus the identity of its source. In this case, if there is an asynchronous bridge that manages a subscription, that bridge can use contiguity to enforce ordering (by keeping sequences in a queue until they become contiguous).
12. Need to wind the faculty for a system-wide ender/error-recoverer into all instances. In general, when something emits an event, that can't fail--the consumer may transmit an error to the sytem-wide, which may result in the source being closed, but the emit execution itself will resolve.
13. Loose end about whether the system-wide controller need truly be system-wide, i.e., is there only one per runtime or might there be multiple sharing different resources?
14. Basically all functions in the core implementation need to delegate *all* errors to their controller, if present. Not implemented yet.
15. Event contracts. 'Consumes' and 'Emits' are currently required, but nothing is done with them. The idea is to warn about compatibility issues between graph components ahead of time. What should a consumer do when it receives an event not registered in Consumes -- ignore it, or throw an error? Should there also be a 'Rejects' list? Or a map of event specs to policies (ACCEPT, IGNORE, REJECT) plus a default policy (ACCEPT, IGNORE, REJECT)? Probably the last one.
16. Concept of 'siphoning'. Usually, it is desirable that a Source should only start fetching data to emit events when it is connected to a Sink. But Derivations blur this distinction because an exterior concern may rely directly on the derived value. In this case, it needs to manually create that pressure by calling a function (perhaps just to create a no-op Sink?). At present, any subscriber creates siphon pressure, even Derivations.
17. Possibility of creating a 'listener', that is, a Sink which does not create siphon pressure, does not close when its Source closes, and does not communicate with the Source's Controller. This could be implemented as an encapsulated Sink which conveys events to an encapsulated Source outside of normal Redound flow.